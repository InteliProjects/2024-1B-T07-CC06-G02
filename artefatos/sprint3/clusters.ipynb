{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Dos Clusters Mapeados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from haversine import haversine\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"../data/amostra_total.csv\", sep=';')\n",
    "\n",
    "# Normalização das coordenadas\n",
    "scaler = StandardScaler()\n",
    "coords = df[['LATITUDE', 'LONGITUDE']].values\n",
    "coords_normalized = scaler.fit_transform(coords)\n",
    "\n",
    "# Primeiro clustering com 350 clusters (leituristas)\n",
    "n_clusters_leituristas = 350\n",
    "kmeans_leituristas = MiniBatchKMeans(n_clusters=n_clusters_leituristas, random_state=88, batch_size=200, n_init='auto')\n",
    "labels_leituristas = kmeans_leituristas.fit_predict(coords_normalized)\n",
    "df.loc[:, 'Cluster_Leiturista'] = labels_leituristas\n",
    "\n",
    "# Segundo clustering dentro de cada cluster de leituristas para 22 subclusters (dias de leitura)\n",
    "n_clusters_dias = 22\n",
    "\n",
    "# Plotar os clusters e subclusters\n",
    "fig = go.Figure()\n",
    "\n",
    "for leiturista in range(n_clusters_leituristas):  # Ajustar para range(n_clusters_leituristas) para leitura total\n",
    "    cluster_data = df[df['Cluster_Leiturista'] == leiturista]\n",
    "    if not cluster_data.empty:\n",
    "        coords_cluster = cluster_data[['LATITUDE', 'LONGITUDE']].values\n",
    "        coords_cluster_normalized = scaler.fit_transform(coords_cluster)\n",
    "        kmeans_dias = MiniBatchKMeans(n_clusters=n_clusters_dias, random_state=88, batch_size=50, n_init='auto')\n",
    "        labels_dias = kmeans_dias.fit_predict(coords_cluster_normalized)\n",
    "        df.loc[cluster_data.index, 'Cluster_Dia'] = labels_dias\n",
    "\n",
    "        # Atualizar cluster_data após adicionar Cluster_Dia\n",
    "        cluster_data = df[df['Cluster_Leiturista'] == leiturista]\n",
    "\n",
    "        # Adicionar círculos representando os subclusters\n",
    "        for dia in range(n_clusters_dias):\n",
    "            subcluster_data = cluster_data[cluster_data['Cluster_Dia'] == dia]\n",
    "            if not subcluster_data.empty:\n",
    "                centroid = subcluster_data[['LATITUDE', 'LONGITUDE']].mean().values\n",
    "                radius = max([haversine(centroid, point) for point in subcluster_data[['LATITUDE', 'LONGITUDE']].values])\n",
    "\n",
    "                fig.add_trace(go.Scattergeo(\n",
    "                    lon=[centroid[1]],\n",
    "                    lat=[centroid[0]],\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=5, color='red', symbol='circle'),\n",
    "                    name=f'Cluster {leiturista} Dia {dia}'\n",
    "                ))\n",
    "\n",
    "                fig.add_trace(go.Scattergeo(\n",
    "                    lon=[centroid[1], centroid[1]],\n",
    "                    lat=[centroid[0], centroid[0] + (radius / 110.574)],  # Convert km to degrees latitude\n",
    "                    mode='lines',\n",
    "                    line=dict(width=2, color='blue'),\n",
    "                    showlegend=False\n",
    "                ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Clusters e Subclusters de Coordenadas Geográficas',\n",
    "    geo=dict(\n",
    "        scope='world',\n",
    "        showland=True\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Dos Resultados Do Algoritmo De Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_route_distance(cluster_data):\n",
    "    # Suponha que cluster_data contém colunas 'LATITUDE' e 'LONGITUDE'\n",
    "    points = list(zip(cluster_data['LATITUDE'], cluster_data['LONGITUDE']))\n",
    "    total_distance = 0.0\n",
    "    for i in range(1, len(points)):\n",
    "        distance = haversine(points[i-1], points[i])  # Define a função haversine se necessário\n",
    "        total_distance += distance\n",
    "    return total_distance\n",
    "\n",
    "# Função para calcular o tempo médio\n",
    "def calculate_average_time(distances, speed_km_h):\n",
    "    total_time = sum(distances) / speed_km_h  # Convertendo distância para tempo\n",
    "    average_time = total_time / len(distances)\n",
    "    return average_time\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_csv(\"amostra_total.csv\", sep=';')\n",
    "scaler = StandardScaler()\n",
    "coords = df[['LATITUDE', 'LONGITUDE']].values\n",
    "coords_normalized = scaler.fit_transform(coords)\n",
    "\n",
    "# Clustering\n",
    "n_clusters = 350  # Ajuste conforme necessário\n",
    "kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=88, batch_size=200)\n",
    "labels = kmeans.fit_predict(coords_normalized)\n",
    "df['Cluster'] = labels\n",
    "\n",
    "# Calcular a distância percorrida por cluster\n",
    "cluster_distances = []\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    total_distance = calculate_route_distance(cluster_data)\n",
    "    cluster_distances.append(total_distance)\n",
    "\n",
    "# Velocidade média de um leiturista (km/h)\n",
    "average_speed = 5  # Ajuste conforme necessário\n",
    "\n",
    "# Calcular tempo médio de distância percorrida\n",
    "average_time = calculate_average_time(cluster_distances, average_speed)\n",
    "\n",
    "# Plotar gráfico de barras horizontal\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.barh(['Tempo Médio de Distância Percorrida'], [average_time])\n",
    "plt.xlabel('Tempo (Minutos)')\n",
    "plt.title('Tempo Médio de Distância Percorrida de Todos os Clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_route_distance(cluster_data):\n",
    "    # Suponha que cluster_data contém colunas 'LATITUDE' e 'LONGITUDE'\n",
    "    points = list(zip(cluster_data['LATITUDE'], cluster_data['LONGITUDE']))\n",
    "    total_distance = 0.0\n",
    "    for i in range(1, len(points)):\n",
    "        distance = haversine(points[i-1], points[i])  # Define a função haversine se necessário\n",
    "        total_distance += distance\n",
    "    return total_distance\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_csv(\"amostra_total.csv\", sep=';')\n",
    "scaler = StandardScaler()\n",
    "coords = df[['LATITUDE', 'LONGITUDE']].values\n",
    "coords_normalized = scaler.fit_transform(coords)\n",
    "\n",
    "# Clustering\n",
    "n_clusters = 350  # Ajuste conforme necessário\n",
    "kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=88, batch_size=200)\n",
    "labels = kmeans.fit_predict(coords_normalized)\n",
    "df['Cluster'] = labels\n",
    "\n",
    "# Calcular a distância percorrida por cluster\n",
    "cluster_distances = []\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    total_distance = calculate_route_distance(cluster_data)\n",
    "    cluster_distances.append(total_distance)\n",
    "\n",
    "# Calcular a média da distância percorrida\n",
    "average_distance = sum(cluster_distances) / len(cluster_distances)\n",
    "\n",
    "# Plotar gráfico de barras horizontal\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.barh(['Média de Distância Percorrida'], [average_distance], color = 'pink')\n",
    "plt.xlabel('Distância no mês (km)')\n",
    "plt.title('Média de Distância Percorrida por Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Com base nos resultados obtidos, o algoritmo processa toda a base de dados, juntamente com as métricas pré-definidas pelo parceiro. Os leituristas conseguem percorrer em média 6 horas por dia, o que resulta em mais de 300 km por mês. Dividindo isso por 22 dias, temos uma média de 13,6 km por dia. Com um ritmo de leitura de 5 minutos por ponto, e considerando que o tempo de execução da célula de clusterização é de cerca de 1 minuto, atende-se quase todos os critérios estabelecidos pelo parceiro, ou fica-se muito próximo de atendê-los."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clusterização da amostra total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "TensorFlow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "#  Importações e Configuração Inicial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Verificar dispositivos TensorFlow\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados:\n",
      "        INDICE   LATITUDE  LONGITUDE CODIGO_ROTA  SEQUENCIA  \\\n",
      "0  401103972.0 -22.858956 -43.338632      70_324     3360.0   \n",
      "1  402281829.0 -22.830781 -43.395010       88_48      309.0   \n",
      "2  400507411.0 -22.821902 -43.415018       74_46      254.0   \n",
      "3  400533412.0 -22.834372 -43.410329       75_57       80.0   \n",
      "4  400515070.0 -22.861150 -43.338667      70_324     3180.0   \n",
      "\n",
      "             LOGRADOURO NUMERO  \n",
      "0  MONS INACIO DA SILVA    545  \n",
      "1           MARIA ELIZA     80  \n",
      "2           DONA LURDES      4  \n",
      "3      LUCIO JOSE FILHO     81  \n",
      "4         MAR DEL PLATA    490  \n"
     ]
    }
   ],
   "source": [
    " #Carregar dados\n",
    "df_total = pd.read_csv('../data/amostra_total.csv', sep=';')\n",
    "print(\"Dados carregados:\")\n",
    "print(df_total.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição dos clusters:\n",
      "Cluster\n",
      "71     2404\n",
      "88     2355\n",
      "15     2310\n",
      "61     2303\n",
      "36     2227\n",
      "267    2172\n",
      "214    2166\n",
      "12     2155\n",
      "226    2092\n",
      "6      1944\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "71     2404\n",
      "88     2355\n",
      "15     2310\n",
      "61     2303\n",
      "36     2227\n",
      "       ... \n",
      "211     536\n",
      "296     530\n",
      "186     529\n",
      "52      489\n",
      "212     334\n",
      "Name: count, Length: 300, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clusterização inicial com MiniBatch K-means\n",
    "coordinates = df_total[['LATITUDE', 'LONGITUDE']]\n",
    "kmeans = MiniBatchKMeans(n_clusters=300, random_state=42, batch_size=10000, n_init=10)\n",
    "kmeans.fit(coordinates)\n",
    "df_total['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Verificar a distribuição dos clusters\n",
    "cluster_distribution = df_total['Cluster'].value_counts()\n",
    "print(\"Distribuição dos clusters:\")\n",
    "print(cluster_distribution.head(10))\n",
    "print(df_total['Cluster'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "71     2404\n",
      "88     2355\n",
      "15     2310\n",
      "61     2303\n",
      "36     2227\n",
      "       ... \n",
      "211     536\n",
      "296     530\n",
      "186     529\n",
      "52      489\n",
      "212     334\n",
      "Name: count, Length: 300, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_total['Cluster'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapa = folium.Map(location=[df_total['LATITUDE'].mean(), df_total['LONGITUDE'].mean()], zoom_start=10)\n",
    "colors = plt.get_cmap('viridis')(np.linspace(0, 1, 300))\n",
    "colors = [mcolors.rgb2hex(color) for color in colors]\n",
    "\n",
    "for _, row in df_total.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['LATITUDE'], row['LONGITUDE']],\n",
    "        radius=5,\n",
    "        color=colors[int(row['Cluster'])],\n",
    "        fill=True\n",
    "    ).add_to(mapa)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame com rotas e dias adicionados e ordenados:\n",
      "        INDICE   LATITUDE  LONGITUDE CODIGO_ROTA  SEQUENCIA  \\\n",
      "0  401103972.0 -22.858956 -43.338632      70_324     3360.0   \n",
      "1  402281829.0 -22.830781 -43.395010       88_48      309.0   \n",
      "2  400507411.0 -22.821902 -43.415018       74_46      254.0   \n",
      "3  400533412.0 -22.834372 -43.410329       75_57       80.0   \n",
      "4  400515070.0 -22.861150 -43.338667      70_324     3180.0   \n",
      "\n",
      "             LOGRADOURO NUMERO  Cluster  Route  Day  \n",
      "0  MONS INACIO DA SILVA    545      164      0    9  \n",
      "1           MARIA ELIZA     80      287      1   21  \n",
      "2           DONA LURDES      4       50      2    9  \n",
      "3      LUCIO JOSE FILHO     81      208      3   16  \n",
      "4         MAR DEL PLATA    490       57      4    4  \n"
     ]
    }
   ],
   "source": [
    "# Adicionar rotas e dias aos clusters e exibir o DataFrame atualizado\n",
    "def add_routes_and_days(df, clusters_column='Cluster', num_days=22):\n",
    "    df['Route'] = -1\n",
    "    df['Day'] = -1\n",
    "    for cluster_id in df[clusters_column].unique():\n",
    "        cluster_data = df[df[clusters_column] == cluster_id].copy()\n",
    "        daily_kmeans = MiniBatchKMeans(n_clusters=num_days, random_state=42)\n",
    "        cluster_data['Day'] = daily_kmeans.fit_predict(cluster_data[['LATITUDE', 'LONGITUDE']])\n",
    "        df.loc[cluster_data.index, 'Route'] = cluster_data.index\n",
    "        df.loc[cluster_data.index, 'Day'] = cluster_data['Day']\n",
    "    return df\n",
    "\n",
    "df_total = add_routes_and_days(df_total)\n",
    "\n",
    "# Ordenar o DataFrame pelas colunas 'Route' e 'Day'\n",
    "df_total_sorted = df_total.sort_values(by=['Route', 'Day'])\n",
    "\n",
    "# Exibir o DataFrame atualizado\n",
    "print(\"DataFrame com rotas e dias adicionados e ordenados:\")\n",
    "print(df_total_sorted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a adição de marcadores ao mapa...\n",
      "Processando ponto 0/378299...\n",
      "Processando ponto 1000/378299...\n",
      "Processando ponto 2000/378299...\n",
      "Processando ponto 3000/378299...\n",
      "Processando ponto 4000/378299...\n",
      "Processando ponto 5000/378299...\n",
      "Processando ponto 6000/378299...\n",
      "Processando ponto 7000/378299...\n",
      "Processando ponto 8000/378299...\n",
      "Processando ponto 9000/378299...\n",
      "Processando ponto 10000/378299...\n",
      "Processando ponto 11000/378299...\n",
      "Processando ponto 12000/378299...\n",
      "Processando ponto 13000/378299...\n",
      "Processando ponto 14000/378299...\n",
      "Processando ponto 15000/378299...\n",
      "Processando ponto 16000/378299...\n",
      "Processando ponto 17000/378299...\n",
      "Processando ponto 18000/378299...\n",
      "Processando ponto 19000/378299...\n",
      "Processando ponto 20000/378299...\n",
      "Processando ponto 21000/378299...\n",
      "Processando ponto 22000/378299...\n",
      "Processando ponto 23000/378299...\n",
      "Processando ponto 24000/378299...\n",
      "Processando ponto 25000/378299...\n",
      "Processando ponto 26000/378299...\n",
      "Processando ponto 27000/378299...\n",
      "Processando ponto 28000/378299...\n",
      "Processando ponto 29000/378299...\n",
      "Processando ponto 30000/378299...\n",
      "Processando ponto 31000/378299...\n",
      "Processando ponto 32000/378299...\n",
      "Processando ponto 33000/378299...\n",
      "Processando ponto 34000/378299...\n",
      "Processando ponto 35000/378299...\n",
      "Processando ponto 36000/378299...\n",
      "Processando ponto 37000/378299...\n",
      "Processando ponto 38000/378299...\n",
      "Processando ponto 39000/378299...\n",
      "Processando ponto 40000/378299...\n",
      "Processando ponto 41000/378299...\n",
      "Processando ponto 42000/378299...\n",
      "Processando ponto 43000/378299...\n",
      "Processando ponto 44000/378299...\n",
      "Processando ponto 45000/378299...\n",
      "Processando ponto 46000/378299...\n"
     ]
    }
   ],
   "source": [
    "# Visualização dos subclusters em um mapa (otimizada com logs)\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "sub_map = folium.Map(location=[df_total['LATITUDE'].mean(), df_total['LONGITUDE'].mean()], zoom_start=12)\n",
    "sub_colors = plt.get_cmap('plasma')(np.linspace(0, 1, 22))\n",
    "sub_colors = [mcolors.rgb2hex(color) for color in sub_colors]\n",
    "\n",
    "print(\"Iniciando a adição de marcadores ao mapa...\")\n",
    "\n",
    "for i, (_, row) in enumerate(df_total.iterrows()):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processando ponto {i}/{len(df_total)}...\")\n",
    "    folium.CircleMarker(\n",
    "        location=[row['LATITUDE'], row['LONGITUDE']],\n",
    "        radius=5,\n",
    "        color=sub_colors[int(row['Day'])],\n",
    "        fill=True,\n",
    "        popup=f'Subcluster: {row[\"Day\"]}'\n",
    "    ).add_to(sub_map)\n",
    "\n",
    "print(\"Todos os marcadores foram adicionados. Salvando o mapa...\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame final salvo como 'clustered_routes_days.csv'\n"
     ]
    }
   ],
   "source": [
    "# Salvar DataFrame final\n",
    "df_total.to_csv('../results/clustered_routes_days.csv', index=False)\n",
    "print(\"DataFrame final salvo como 'clustered_routes_days.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
